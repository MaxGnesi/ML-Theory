Youâ€™re absolutely right - the parameters appear without explanation! Let me add a comprehensive **Parameter Guide** section that clearly explains where each parameter comes from and what it represents.

-----

# ğŸ¯ **The Complete Gradient Descent Family: Sequential Walkthrough**

## ğŸ“‹ Setup: Data & Goal

|                    |                                                                    |
|--------------------|--------------------------------------------------------------------|
|**Data Points**     |Point 1: (2,10), Point 2: (1,5), Point 3: (3,15), Point 4: (0.5,2.5)|
|**Starting Weight** |w = 3                                                               |
|**True Weight**     |w = 5 (our target)                                                  |
|**Loss Function**   |L = (prediction - y_true)Â²                                          |
|**Gradient Formula**|âˆ‚L/âˆ‚w = 2 Ã— (prediction - y_true) Ã— x                               |

-----

## ğŸ”§ **Parameter Guide: What Are These Numbers?**

Parameters fall into two categories:

**ğŸ›ï¸ Hyperparameters** = Values YOU choose before training (tunable)  
**ğŸ“Š State Variables** = Values the algorithm computes and updates during training

-----

### **Method 1: SGD (Stochastic Gradient Descent)**

|Parameter  |Type            |Value|What It Represents                                                                                                    |
|-----------|----------------|-----|----------------------------------------------------------------------------------------------------------------------|
|**Î·** (eta)|ğŸ›ï¸ Hyperparameter|0.1  |**Learning rate** - How big a step to take. Too high â†’ overshoot. Too low â†’ slow learning. Typical range: 0.001 to 0.1|

**Update Rule**: `w_new = w_old - Î· Ã— gradient`

*SGD is the simplest - just one knob to turn!*

-----

### **Method 2: Momentum**

|Parameter   |Type            |Value      |What It Represents                                                                                                                            |
|------------|----------------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------|
|**Î·**       |ğŸ›ï¸ Hyperparameter|0.1        |Learning rate                                                                                                                                 |
|**Î²** (beta)|ğŸ›ï¸ Hyperparameter|0.9        |**Momentum coefficient** - How much â€œmemoryâ€ of past gradients to keep. 0.9 means 90% of previous velocity carries forward. Range: 0.5 to 0.99|
|**v**       |ğŸ“Š State Variable|starts at 0|**Velocity** - Accumulated momentum from past gradients. Think of it as the â€œspeedâ€ the optimizer has built up                                |

**Update Rules**:

```
v_new = Î² Ã— v_old + gradient          â† Accumulate momentum
w_new = w_old - Î· Ã— v_new              â† Apply velocity to weights
```

**Intuition**: Like a ball rolling downhill - it builds speed and can roll through small bumps (noisy gradients), but might overshoot valleys.

-----

### **Method 3: AdaGrad (Adaptive Gradient)**

|Parameter      |Type            |Value      |What It Represents                                                                                      |
|---------------|----------------|-----------|--------------------------------------------------------------------------------------------------------|
|**Î·**          |ğŸ›ï¸ Hyperparameter|0.1        |Base learning rate (gets divided by âˆšG)                                                                 |
|**Îµ** (epsilon)|ğŸ›ï¸ Hyperparameter|1e-8       |**Numerical stability constant** - Prevents division by zero. Always tiny (10â»â¸)                        |
|**G**          |ğŸ“Š State Variable|starts at 0|**Accumulated squared gradients** - Sum of ALL squared gradients seen so far. Only grows, never shrinks!|

**Update Rules**:

```
G_new = G_old + gradientÂ²              â† Accumulate squared gradients (forever!)
effective_lr = Î· / âˆš(G + Îµ)            â† Learning rate shrinks as G grows
w_new = w_old - effective_lr Ã— gradient
```

**Intuition**: Parameters that get large gradients frequently get smaller learning rates. Good for sparse data, but G never stops growing â†’ learning eventually freezes.

-----

### **Method 4: RMSprop (Root Mean Square Propagation)**

|Parameter  |Type            |Value      |What It Represents                                                                                                       |
|-----------|----------------|-----------|-------------------------------------------------------------------------------------------------------------------------|
|**Î·**      |ğŸ›ï¸ Hyperparameter|0.1        |Base learning rate                                                                                                       |
|**Ï** (rho)|ğŸ›ï¸ Hyperparameter|0.9        |**Decay rate** - How quickly to â€œforgetâ€ old gradients. 0.9 keeps 90% of old average, adds 10% of new. Range: 0.9 to 0.99|
|**Îµ**      |ğŸ›ï¸ Hyperparameter|1e-8       |Numerical stability constant                                                                                             |
|**E[gÂ²]**  |ğŸ“Š State Variable|starts at 0|**Exponential moving average of squared gradients** - Unlike AdaGradâ€™s G, this DECAYS over time                          |

**Update Rules**:

```
E[gÂ²]_new = Ï Ã— E[gÂ²]_old + (1-Ï) Ã— gradientÂ²   â† Decaying average
effective_lr = Î· / âˆš(E[gÂ²] + Îµ)
w_new = w_old - effective_lr Ã— gradient
```

**Intuition**: Fixes AdaGradâ€™s freezing problem by using a â€œleakyâ€ memory. Old large gradients fade away, so learning rate can recover.

**Why Ï = 0.9?** This means the effective â€œwindowâ€ of memory is about 10 gradients. After ~10 updates, old gradients have faded to <35% influence.

-----

### **Method 5: Adam (Adaptive Moment Estimation)**

|Parameter|Type            |Value      |What It Represents                                                                                              |
|---------|----------------|-----------|----------------------------------------------------------------------------------------------------------------|
|**Î·**    |ğŸ›ï¸ Hyperparameter|0.1        |Base learning rate                                                                                              |
|**Î²â‚**   |ğŸ›ï¸ Hyperparameter|0.9        |**First moment decay** - Controls momentum-like behavior. Same as RMSpropâ€™s Ï but for the gradient itself       |
|**Î²â‚‚**   |ğŸ›ï¸ Hyperparameter|0.999      |**Second moment decay** - Controls gradient magnitude scaling. Higher than Î²â‚ = longer memory for variance      |
|**Îµ**    |ğŸ›ï¸ Hyperparameter|1e-8       |Numerical stability constant                                                                                    |
|**m**    |ğŸ“Š State Variable|starts at 0|**First moment (mean)** - Exponential moving average of gradients (like momentumâ€™s velocity)                    |
|**v**    |ğŸ“Š State Variable|starts at 0|**Second moment (uncentered variance)** - Exponential moving average of squared gradients (like RMSpropâ€™s E[gÂ²])|
|**t**    |ğŸ“Š State Variable|starts at 0|**Timestep counter** - Counts how many updates weâ€™ve done. Used for bias correction                             |

**Update Rules**:

```
t = t + 1                                        â† Increment timestep

m_new = Î²â‚ Ã— m_old + (1-Î²â‚) Ã— gradient          â† Update first moment (direction)
v_new = Î²â‚‚ Ã— v_old + (1-Î²â‚‚) Ã— gradientÂ²         â† Update second moment (magnitude)

mÌ‚ = m_new / (1 - Î²â‚áµ—)                           â† Bias-corrected first moment
vÌ‚ = v_new / (1 - Î²â‚‚áµ—)                           â† Bias-corrected second moment

w_new = w_old - Î· Ã— mÌ‚ / âˆš(vÌ‚ + Îµ)               â† Final update
```

**Why bias correction?** At t=1, if Î²â‚=0.9:

- `m = 0.9 Ã— 0 + 0.1 Ã— gradient = 0.1 Ã— gradient` (way too small!)
- Dividing by `(1 - 0.9Â¹) = 0.1` recovers the full gradient magnitude

As t â†’ âˆ, `(1 - Î²â‚áµ—) â†’ 1`, so correction fades away.

**Why Î²â‚‚ = 0.999 > Î²â‚ = 0.9?** We want the variance estimate to be more stable (longer memory) than the momentum (can respond faster to direction changes).

-----

## ğŸ“Š **Parameter Summary Table**

|Method      |Hyperparameters|State Variables           |Key Idea                            |
|------------|---------------|--------------------------|------------------------------------|
|**SGD**     |Î·              |none                      |Simple scaled step                  |
|**Momentum**|Î·, Î²           |v (velocity)              |Build up speed                      |
|**AdaGrad** |Î·, Îµ           |G (sum of gÂ²)             |Adapt LR per-parameter, but freezes |
|**RMSprop** |Î·, Ï, Îµ        |E[gÂ²] (decaying avg of gÂ²)|AdaGrad + forgetting                |
|**Adam**    |Î·, Î²â‚, Î²â‚‚, Îµ   |m, v, t                   |Momentum + RMSprop + bias correction|

-----

## ğŸ¯ **Standard Default Values**

These values work well in ~80% of cases:

|Hyperparameter        |Default|When to Change                                     |
|----------------------|-------|---------------------------------------------------|
|**Î·** (learning rate) |0.001  |Increase if learning too slow, decrease if unstable|
|**Î²** (momentum)      |0.9    |Lower (0.5-0.8) if oscillating too much            |
|**Ï** (RMSprop decay) |0.9    |Rarely changed                                     |
|**Î²â‚** (Adam momentum)|0.9    |Rarely changed                                     |
|**Î²â‚‚** (Adam variance)|0.999  |Rarely changed                                     |
|**Îµ**                 |1e-8   |Almost never changed                               |

-----

Now that we understand where every parameter comes from, letâ€™s see them in action!

-----

## ğŸ“ **POINT 1: (x=2, y=10)**

### **Method 1: SGD**

```
Parameters used: Î· = 0.1

Current w: 3
Prediction: w Ã— x = 3 Ã— 2 = 6
Error: prediction - y = 6 - 10 = -4
Gradient: 2 Ã— error Ã— x = 2 Ã— (-4) Ã— 2 = -16

Update: w = w - Î· Ã— gradient
        w = 3 - (0.1 Ã— -16) = 3 + 1.6 = 4.6
```

âœ… **Result**: w = **4.6**

-----

### **Method 2: Momentum**

```
Parameters used: Î· = 0.1, Î² = 0.9
State variables: v = 0 (initialized)

Current w: 3
Prediction: 3 Ã— 2 = 6
Error: 6 - 10 = -4
Gradient: 2 Ã— (-4) Ã— 2 = -16

Velocity Update: v = Î² Ã— v_old + gradient
                 v = 0.9 Ã— 0 + (-16) = -16

Weight Update: w = w - Î· Ã— v
               w = 3 - (0.1 Ã— -16) = 4.6
```

âœ… **Result**: w = **4.6**, v = **-16**

*Same as SGD on first step since v started at 0!*

-----

### **Method 3: AdaGrad**

```
Parameters used: Î· = 0.1, Îµ = 1e-8
State variables: G = 0 (initialized)

Current w: 3
Prediction: 3 Ã— 2 = 6
Error: 6 - 10 = -4
Gradient: 2 Ã— (-4) Ã— 2 = -16

G Update: G = G_old + gradientÂ²
          G = 0 + (-16)Â² = 256

Effective LR: Î· / âˆš(G + Îµ) = 0.1 / âˆš256 = 0.1 / 16 = 0.00625

Weight Update: w = w - effective_lr Ã— gradient
               w = 3 - (0.00625 Ã— -16) = 3 + 0.1 = 3.1
```

âœ… **Result**: w = **3.1**, G = **256**

*Much smaller step because gradient was large â†’ G is large â†’ LR shrinks!*

-----

### **Method 4: RMSprop**

```
Parameters used: Î· = 0.1, Ï = 0.9, Îµ = 1e-8
State variables: E[gÂ²] = 0 (initialized)

Current w: 3
Prediction: 3 Ã— 2 = 6
Error: 6 - 10 = -4
Gradient: 2 Ã— (-4) Ã— 2 = -16

E[gÂ²] Update: E[gÂ²] = Ï Ã— E[gÂ²]_old + (1-Ï) Ã— gradientÂ²
              E[gÂ²] = 0.9 Ã— 0 + 0.1 Ã— (-16)Â² = 0 + 25.6 = 25.6

Effective LR: Î· / âˆš(E[gÂ²] + Îµ) = 0.1 / âˆš25.6 = 0.1 / 5.06 â‰ˆ 0.0198

Weight Update: w = 3 - (0.0198 Ã— -16) = 3 + 0.317 â‰ˆ 3.317
```

âœ… **Result**: w = **3.317**, E[gÂ²] = **25.6**

*Bigger step than AdaGrad! E[gÂ²] = 25.6 vs G = 256 (only kept 10% of squared gradient)*

-----

### **Method 5: Adam**

```
Parameters used: Î· = 0.1, Î²â‚ = 0.9, Î²â‚‚ = 0.999, Îµ = 1e-8
State variables: m = 0, v = 0, t = 0 (initialized)

Current w: 3
t = 0 + 1 = 1 (increment timestep)

Prediction: 3 Ã— 2 = 6
Error: 6 - 10 = -4
Gradient: 2 Ã— (-4) Ã— 2 = -16

First Moment: m = Î²â‚ Ã— m_old + (1-Î²â‚) Ã— gradient
              m = 0.9 Ã— 0 + 0.1 Ã— (-16) = -1.6

Second Moment: v = Î²â‚‚ Ã— v_old + (1-Î²â‚‚) Ã— gradientÂ²
               v = 0.999 Ã— 0 + 0.001 Ã— (-16)Â² = 0.256

Bias Correction (crucial at early timesteps!):
  mÌ‚ = m / (1 - Î²â‚áµ—) = -1.6 / (1 - 0.9Â¹) = -1.6 / 0.1 = -16
  vÌ‚ = v / (1 - Î²â‚‚áµ—) = 0.256 / (1 - 0.999Â¹) = 0.256 / 0.001 = 256

Weight Update: w = w - Î· Ã— mÌ‚ / âˆš(vÌ‚ + Îµ)
               w = 3 - 0.1 Ã— (-16) / âˆš256 
               w = 3 + 1.6 / 16 = 3.1
```

âœ… **Result**: w = **3.1**, m = **-1.6**, v = **0.256**, t = **1**

*Bias correction scaled m from -1.6 back to -16 and v from 0.256 to 256!*

-----

## ğŸ“ **POINT 2: (x=1, y=5)**

### **Method 1: SGD**

```
Parameters: Î· = 0.1
Current w: 4.6

Prediction: 4.6 Ã— 1 = 4.6
Error: 4.6 - 5 = -0.4
Gradient: 2 Ã— (-0.4) Ã— 1 = -0.8

Update: w = 4.6 - (0.1 Ã— -0.8) = 4.6 + 0.08 = 4.68
```

âœ… **Result**: w = **4.68**

-----

### **Method 2: Momentum**

```
Parameters: Î· = 0.1, Î² = 0.9
State: v = -16 (from Point 1)
Current w: 4.6

Prediction: 4.6 Ã— 1 = 4.6
Error: 4.6 - 5 = -0.4
Gradient: 2 Ã— (-0.4) Ã— 1 = -0.8

Velocity: v = 0.9 Ã— (-16) + (-0.8) = -14.4 - 0.8 = -15.2
          â†‘ 90% of old momentum carried forward!

Weight: w = 4.6 - (0.1 Ã— -15.2) = 4.6 + 1.52 = 6.12
```

âœ… **Result**: w = **6.12**, v = **-15.2**

*ğŸš€ OVERSHOOT! The old velocity (-16) dominated the tiny new gradient (-0.8)*

-----

### **Method 3: AdaGrad**

```
Parameters: Î· = 0.1, Îµ = 1e-8
State: G = 256 (from Point 1)
Current w: 3.1

Prediction: 3.1 Ã— 1 = 3.1
Error: 3.1 - 5 = -1.9
Gradient: 2 Ã— (-1.9) Ã— 1 = -3.8

G Update: G = 256 + (-3.8)Â² = 256 + 14.44 = 270.44
          â†‘ G only ever grows!

Effective LR: 0.1 / âˆš270.44 = 0.1 / 16.45 â‰ˆ 0.00608

Weight: w = 3.1 - (0.00608 Ã— -3.8) = 3.1 + 0.023 â‰ˆ 3.123
```

âœ… **Result**: w = **3.123**, G = **270.44**

*Learning rate already dying: 0.00608 vs original 0.1*

-----

### **Method 4: RMSprop**

```
Parameters: Î· = 0.1, Ï = 0.9, Îµ = 1e-8
State: E[gÂ²] = 25.6 (from Point 1)
Current w: 3.317

Prediction: 3.317 Ã— 1 = 3.317
Error: 3.317 - 5 = -1.683
Gradient: 2 Ã— (-1.683) Ã— 1 = -3.366

E[gÂ²] Update: E[gÂ²] = 0.9 Ã— 25.6 + 0.1 Ã— (-3.366)Â²
                     = 23.04 + 1.133 = 24.173
              â†‘ Old value DECAYED by 0.9, only kept 90%

Effective LR: 0.1 / âˆš24.173 â‰ˆ 0.0203

Weight: w = 3.317 + (0.0203 Ã— 3.366) = 3.317 + 0.068 â‰ˆ 3.386
```

âœ… **Result**: w = **3.386**, E[gÂ²] = **24.173**

*E[gÂ²] actually decreased (25.6 â†’ 24.17)! LR can recover.*

-----

### **Method 5: Adam**

```
Parameters: Î· = 0.1, Î²â‚ = 0.9, Î²â‚‚ = 0.999, Îµ = 1e-8
State: m = -1.6, v = 0.256, t = 1 (from Point 1)
Current w: 3.1

t = 2 (increment)

Prediction: 3.1 Ã— 1 = 3.1
Error: 3.1 - 5 = -1.9
Gradient: 2 Ã— (-1.9) Ã— 1 = -3.8

First Moment: m = 0.9 Ã— (-1.6) + 0.1 Ã— (-3.8) = -1.44 - 0.38 = -1.82
Second Moment: v = 0.999 Ã— 0.256 + 0.001 Ã— (-3.8)Â² = 0.256 + 0.014 = 0.270

Bias Correction:
  mÌ‚ = -1.82 / (1 - 0.9Â²) = -1.82 / 0.19 = -9.58
  vÌ‚ = 0.270 / (1 - 0.999Â²) = 0.270 / 0.002 = 135

Weight: w = 3.1 - 0.1 Ã— (-9.58) / âˆš135 = 3.1 + 0.958/11.6 = 3.1 + 0.083 â‰ˆ 3.183
```

âœ… **Result**: w = **3.183**, m = **-1.82**, v = **0.270**, t = **2**

-----

## ğŸ“ **POINT 3: (x=3, y=15)**

### **Method 1: SGD**

```
Current w: 4.68

Prediction: 4.68 Ã— 3 = 14.04
Error: 14.04 - 15 = -0.96
Gradient: 2 Ã— (-0.96) Ã— 3 = -5.76

Update: w = 4.68 + (0.1 Ã— 5.76) = 4.68 + 0.576 = 5.256
```

âœ… **Result**: w = **5.256**

-----

### **Method 2: Momentum**

```
State: v = -15.2, Current w: 6.12

Prediction: 6.12 Ã— 3 = 18.36
Error: 18.36 - 15 = +3.36 â† POSITIVE! We overshot!
Gradient: 2 Ã— (3.36) Ã— 3 = +20.16

Velocity: v = 0.9 Ã— (-15.2) + 20.16 = -13.68 + 20.16 = +6.48
          â†‘ Velocity REVERSED direction!

Weight: w = 6.12 - (0.1 Ã— 6.48) = 6.12 - 0.648 = 5.472
```

âœ… **Result**: w = **5.472**, v = **+6.48**

*Momentum is now pulling back toward target*

-----

### **Method 3: AdaGrad**

```
State: G = 270.44, Current w: 3.123

Prediction: 3.123 Ã— 3 = 9.369
Error: 9.369 - 15 = -5.631
Gradient: 2 Ã— (-5.631) Ã— 3 = -33.786

G Update: G = 270.44 + 1141.5 = 1411.94
          â†‘ HUGE jump from one big gradient!

Effective LR: 0.1 / âˆš1411.94 = 0.1 / 37.58 â‰ˆ 0.00266

Weight: w = 3.123 + (0.00266 Ã— 33.786) = 3.123 + 0.090 â‰ˆ 3.213
```

âœ… **Result**: w = **3.213**, G = **1411.94**

*Learning rate is now 2.7% of original! Nearly frozen.*

-----

### **Method 4: RMSprop**

```
State: E[gÂ²] = 24.173, Current w: 3.386

Prediction: 3.386 Ã— 3 = 10.158
Error: 10.158 - 15 = -4.842
Gradient: 2 Ã— (-4.842) Ã— 3 = -29.052

E[gÂ²] Update: E[gÂ²] = 0.9 Ã— 24.173 + 0.1 Ã— 844 = 21.76 + 84.4 = 106.16

Effective LR: 0.1 / âˆš106.16 â‰ˆ 0.0097

Weight: w = 3.386 + (0.0097 Ã— 29.052) = 3.386 + 0.282 â‰ˆ 3.668
```

âœ… **Result**: w = **3.668**, E[gÂ²] = **106.16**

-----

### **Method 5: Adam**

```
State: m = -1.82, v = 0.270, t = 2
Current w: 3.183

t = 3

Prediction: 3.183 Ã— 3 = 9.549
Error: 9.549 - 15 = -5.451
Gradient: 2 Ã— (-5.451) Ã— 3 = -32.706

First Moment: m = 0.9 Ã— (-1.82) + 0.1 Ã— (-32.706) = -1.64 - 3.27 = -4.91
Second Moment: v = 0.999 Ã— 0.270 + 0.001 Ã— 1069.7 = 0.270 + 1.07 = 1.34

Bias Correction:
  mÌ‚ = -4.91 / (1 - 0.729) = -4.91 / 0.271 = -18.12
  vÌ‚ = 1.34 / (1 - 0.997) = 1.34 / 0.003 = 446.7

Weight: w = 3.183 - 0.1 Ã— (-18.12) / âˆš446.7 = 3.183 + 1.81/21.1 = 3.183 + 0.086 â‰ˆ 3.27
```

âœ… **Result**: w = **3.27**, m = **-4.91**, v = **1.34**, t = **3**

-----

## ğŸ“ **POINT 4: (x=0.5, y=2.5)**

### **Method 1: SGD**

```
Current w: 5.256

Prediction: 5.256 Ã— 0.5 = 2.628
Error: 2.628 - 2.5 = +0.128 â† Slightly above target
Gradient: 2 Ã— (0.128) Ã— 0.5 = +0.128

Update: w = 5.256 - (0.1 Ã— 0.128) = 5.256 - 0.0128 = 5.243
```

âœ… **Final w = 5.243** âœ¨

-----

### **Method 2: Momentum**

```
State: v = +6.48, Current w: 5.472

Prediction: 5.472 Ã— 0.5 = 2.736
Error: 2.736 - 2.5 = +0.236
Gradient: 2 Ã— (0.236) Ã— 0.5 = +0.236

Velocity: v = 0.9 Ã— 6.48 + 0.236 = 5.83 + 0.24 = 6.07
          â†‘ Still pushing w DOWN (positive v â†’ subtract from w)

Weight: w = 5.472 - (0.1 Ã— 6.07) = 5.472 - 0.607 = 4.865
```

âœ… **Final w = 4.865** âœ¨

*Undershot! Momentum kept pushing past 5*

-----

### **Method 3: AdaGrad**

```
State: G = 1411.94, Current w: 3.213

Prediction: 3.213 Ã— 0.5 = 1.607
Error: 1.607 - 2.5 = -0.893
Gradient: 2 Ã— (-0.893) Ã— 0.5 = -0.893

G Update: G = 1411.94 + 0.80 = 1412.74

Effective LR: 0.1 / âˆš1412.74 = 0.00266

Weight: w = 3.213 + (0.00266 Ã— 0.893) = 3.213 + 0.0024 â‰ˆ 3.216
```

âœ… **Final w = 3.216** ğŸ˜¢

*Moved only 0.003 - completely frozen!*

-----

### **Method 4: RMSprop**

```
State: E[gÂ²] = 106.16, Current w: 3.668

Prediction: 3.668 Ã— 0.5 = 1.834
Error: 1.834 - 2.5 = -0.666
Gradient: 2 Ã— (-0.666) Ã— 0.5 = -0.666

E[gÂ²] Update: E[gÂ²] = 0.9 Ã— 106.16 + 0.1 Ã— 0.44 = 95.5 + 0.04 = 95.59
              â†‘ Decayed! LR will recover over time

Effective LR: 0.1 / âˆš95.59 â‰ˆ 0.0102

Weight: w = 3.668 + (0.0102 Ã— 0.666) = 3.668 + 0.0068 â‰ˆ 3.675
```

âœ… **Final w = 3.675**

-----

### **Method 5: Adam**

```
State: m = -4.91, v = 1.34, t = 3
Current w: 3.27

t = 4

Prediction: 3.27 Ã— 0.5 = 1.635
Error: 1.635 - 2.5 = -0.865
Gradient: 2 Ã— (-0.865) Ã— 0.5 = -0.865

First Moment: m = 0.9 Ã— (-4.91) + 0.1 Ã— (-0.865) = -4.42 - 0.09 = -4.51
Second Moment: v = 0.999 Ã— 1.34 + 0.001 Ã— 0.75 = 1.34 + 0.001 = 1.34

Bias Correction:
  mÌ‚ = -4.51 / (1 - 0.6561) = -4.51 / 0.344 = -13.11
  vÌ‚ = 1.34 / (1 - 0.996) = 1.34 / 0.004 = 335

Weight: w = 3.27 - 0.1 Ã— (-13.11) / âˆš335 = 3.27 + 1.31/18.3 = 3.27 + 0.072 â‰ˆ 3.34
```

âœ… **Final w = 3.34**

-----

## ğŸ† **Final Scoreboard After 1 Epoch**

|Method      |Final w|Distance from 5|Key Behavior                       |
|------------|-------|---------------|-----------------------------------|
|**SGD**     |5.243  |0.243          |Fast but noisy                     |
|**Momentum**|4.865  |0.135          |Overshot then corrected            |
|**AdaGrad** |3.216  |1.784          |**FROZEN** (G too large)           |
|**RMSprop** |3.675  |1.325          |Slow but recovering                |
|**Adam**    |3.34   |1.66           |Conservative early, will accelerate|

-----

## ğŸ’¡ **Key Insights from Parameter Behavior**

1. **SGD**: Î· alone controls everything - simple but no adaptation
1. **Momentum**: v accumulates history â†’ can overshoot when gradient reverses. Î²=0.9 means 90% of old velocity persists
1. **AdaGrad**: G only grows â†’ LR only shrinks â†’ eventually frozen. The big gradient (-16) at Point 1 permanently damaged the learning rate
1. **RMSprop**: E[gÂ²] decays by Ï=0.9 each step â†’ old gradients fade â†’ LR can recover
1. **Adam**: Bias correction is crucial early (t=1,2,3â€¦). Without it, m and v would be too small and updates would be wrong

-----

Is this clearer? Would you like me to continue with more epochs to show how Adam eventually catches up?â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹
